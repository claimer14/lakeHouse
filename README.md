# Lakehouse Toy Project

## Описание проекта
Проект представляет собой реализацию Lakehouse архитектуры с использованием Apache Spark и Delta Lake. Включает в себя полный ETL-пайплайн с тремя слоями (bronze, silver, gold) и интеграцию с MLflow для логирования моделей машинного обучения.

## Архитектура проекта
```
.
├── data/                    # Директория для данных
│   ├── bronze/             # Сырые данные
│   ├── silver/             # Очищенные данные
│   └── gold/               # Агрегированные данные и результаты ML
├── src/                    # Исходный код
│   └── main/
│       └── python/
│           ├── bronze_layer.py    # Генерация и загрузка данных
│           ├── silver_layer.py    # Очистка и обработка
│           └── gold_layer.py      # Агрегации и ML
├── logs/                   # Логи приложения
├── docker-compose.yml      # Конфигурация Docker
├── Dockerfile             # Сборка Spark приложения
├── Dockerfile.mlflow      # Сборка MLflow сервера
└── requirements.txt       # Зависимости Python
```

## Требования
- Docker
- Docker Compose

## Запуск проекта
1. Клонируйте репозиторий:
```bash
git clone <repository-url>
cd lab3_lakehouse
```

2. Запустите проект:
```bash
docker-compose up --build
```

## Компоненты проекта

### 1. Bronze Layer
- Генерация синтетических данных (100,000 записей)
- Признаки:
  - Числовые: возраст, доход, сумма покупки
  - Категориальные: образование, категория товара
  - Временные: дата покупки
- Сохранение в Delta Lake format

### 2. Silver Layer
- Очистка данных:
  - Удаление дубликатов
  - Обработка пропущенных значений
- Обогащение данных:
  - Добавление возрастных групп
  - Категоризация дохода
  - Извлечение временных признаков

### 3. Gold Layer
- Агрегации:
  - По категориям товаров
  - По демографическим группам
  - По временным периодам
- Машинное обучение:
  - RandomForestRegressor для предсказания суммы покупки
  - Логирование в MLflow

## MLflow UI
После запуска проекта, MLflow UI доступен по адресу:
```
http://localhost:5000
```

## Особенности реализации
- Использование Delta Lake для всех слоев данных
- Оптимизация Spark с помощью repartition
- Полная интеграция с MLflow для логирования моделей
- Автоматизированный пайплайн в Docker

## Требования лабораторной работы
- [x] Датасет (100,000+ строк, 6+ признаков)
- [x] Spark в локальном режиме
- [x] Delta Lake Lakehouse
- [x] ETL-pipeline
- [x] Машинное обучение с MLflow
- [x] Структура проекта
- [x] Простота запуска
- [x] Анализ данных
- [x] Оптимизации Spark
- [x] Оптимизации Delta Lake
